{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J060_Test_1_DL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohammhatre001/Assignments/blob/master/J060_Test_1_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvsK9H1f-zrr",
        "colab_type": "text"
      },
      "source": [
        "**Deep Learning Test 1: J060**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3lbEseKtBSh",
        "colab_type": "code",
        "outputId": "60493f92-5485-4cc8-c9cc-e330fb236d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.2250 - acc: 0.9308 - val_loss: 0.1272 - val_acc: 0.9618\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0837 - acc: 0.9744 - val_loss: 0.1018 - val_acc: 0.9688\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0549 - acc: 0.9819 - val_loss: 0.0744 - val_acc: 0.9774\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0395 - acc: 0.9875 - val_loss: 0.0727 - val_acc: 0.9781\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0295 - acc: 0.9909 - val_loss: 0.0738 - val_acc: 0.9789\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0228 - acc: 0.9928 - val_loss: 0.0741 - val_acc: 0.9812\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0802 - val_acc: 0.9818\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0888 - val_acc: 0.9802\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0775 - val_acc: 0.9828\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0110 - acc: 0.9966 - val_loss: 0.1133 - val_acc: 0.9809\n",
            "Test loss: 0.11330270703719197\n",
            "Test accuracy: 0.9809\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzxvYfLIxzax",
        "colab_type": "code",
        "outputId": "84670335-30dd-41c8-e5d1-34a97096d053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)\n",
        "\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0907 - val_acc: 0.9827\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0866 - val_acc: 0.9838\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0847 - val_acc: 0.9839\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0836 - val_acc: 0.9840\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0828 - val_acc: 0.9841\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0821 - val_acc: 0.9843\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0817 - val_acc: 0.9846\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0814 - val_acc: 0.9845\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0811 - val_acc: 0.9845\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 9.7234e-04 - acc: 0.9999 - val_loss: 0.0809 - val_acc: 0.9846\n",
            "Test loss: 0.08093289872509266\n",
            "Test accuracy: 0.9846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdnzt3ZA-Vpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItLp74QwzATf",
        "colab_type": "text"
      },
      "source": [
        "**SGD**\n",
        "\n",
        "Test loss: 0.08664665951977013\n",
        "\n",
        "\n",
        "Test accuracy: 0.9847"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhHi5SE1x3bN",
        "colab_type": "code",
        "outputId": "7788753d-1a2d-4eb2-9787-65f523d628ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0914 - val_acc: 0.9823\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0085 - acc: 0.9975 - val_loss: 0.0989 - val_acc: 0.9819\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.1067 - val_acc: 0.9829\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.1107 - val_acc: 0.9827\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.1203 - val_acc: 0.9815\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.1215 - val_acc: 0.9815\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.1043 - val_acc: 0.9839\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.1174 - val_acc: 0.9828\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.1465 - val_acc: 0.9797\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.1283 - val_acc: 0.9831\n",
            "Test loss: 0.12828052789145944\n",
            "Test accuracy: 0.9831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39V1aMguzM5_",
        "colab_type": "text"
      },
      "source": [
        "**RMSprop**\n",
        "\n",
        "Test loss: 0.12649620679515766\n",
        "\n",
        "\n",
        "Test accuracy: 0.984"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqC0OdUMyDvV",
        "colab_type": "code",
        "outputId": "5cb99a9f-ccee-4296-c48b-cc867128e951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0250 - acc: 0.9961 - val_loss: 0.1139 - val_acc: 0.9840\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.1048 - val_acc: 0.9852\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 3.5984e-04 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9853\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.9198e-04 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9851\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8797e-04 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9851\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8563e-04 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9851\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8397e-04 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9850\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8269e-04 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9851\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.8168e-04 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9852\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8083e-04 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9852\n",
            "Test loss: 0.10537118407408669\n",
            "Test accuracy: 0.9852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ytjhMMtz2Gw",
        "colab_type": "text"
      },
      "source": [
        "**Adagard**\n",
        "\n",
        "Test loss: 0.10811926535155592\n",
        "\n",
        "\n",
        "Test accuracy: 0.9848"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byDFsBzDyaOs",
        "colab_type": "code",
        "outputId": "45b84e0c-c73e-4b92-c4ae-57df8a0c7e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 2.8020e-04 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9854\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7837e-04 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9853\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7723e-04 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9852\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7637e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9853\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7572e-04 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7520e-04 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9852\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7477e-04 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 0.9852\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7440e-04 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9852\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7408e-04 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9854\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 2.7380e-04 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 0.9853\n",
            "Test loss: 0.10743185467853994\n",
            "Test accuracy: 0.9853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKZtI_O6z8rN",
        "colab_type": "text"
      },
      "source": [
        "**Adadelta**\n",
        "\n",
        "Test loss: 0.10811314213337339\n",
        "\n",
        "\n",
        "Test accuracy: 0.985"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoDsuqIyffM",
        "colab_type": "code",
        "outputId": "58e9ce87-2765-47ab-9cc6-f77ca1bb2e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0168 - acc: 0.9959 - val_loss: 0.1294 - val_acc: 0.9797\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0145 - acc: 0.9958 - val_loss: 0.1068 - val_acc: 0.9815\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.1080 - val_acc: 0.9821\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0118 - acc: 0.9965 - val_loss: 0.1119 - val_acc: 0.9811\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.1270 - val_acc: 0.9785\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.1134 - val_acc: 0.9790\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.1252 - val_acc: 0.9812\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0118 - acc: 0.9966 - val_loss: 0.1039 - val_acc: 0.9821\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.1119 - val_acc: 0.9810\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.1010 - val_acc: 0.9808\n",
            "Test loss: 0.10096633430286252\n",
            "Test accuracy: 0.9808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRQClsAd0Eet",
        "colab_type": "text"
      },
      "source": [
        "**Adam**\n",
        "\n",
        "Test loss: 0.11245599556569041\n",
        "\n",
        "\n",
        "Test accuracy: 0.9806"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NtYY-P3ylvs",
        "colab_type": "code",
        "outputId": "2e69c5bc-2bfc-4ca2-91eb-69288792ed88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 3.8344e-04 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 0.9865\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6949e-04 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9864\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6905e-04 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9863\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6889e-04 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9862\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.6885e-04 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9862\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6882e-04 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9863\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6880e-04 - acc: 1.0000 - val_loss: 0.1067 - val_acc: 0.9864\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6879e-04 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9864\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9865\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9865\n",
            "Test loss: 0.10938909584375263\n",
            "Test accuracy: 0.9865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139637814631504 -->\n<g class=\"node\" id=\"node1\">\n<title>139637814631504</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 139638800351472 -->\n<g class=\"node\" id=\"node2\">\n<title>139638800351472</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 139637814631504&#45;&gt;139638800351472 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139637814631504-&gt;139638800351472</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139637814631112 -->\n<g class=\"node\" id=\"node3\">\n<title>139637814631112</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 139638800351472&#45;&gt;139637814631112 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139638800351472-&gt;139637814631112</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139637801619128 -->\n<g class=\"node\" id=\"node4\">\n<title>139637801619128</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 139637814631112&#45;&gt;139637801619128 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139637814631112-&gt;139637801619128</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXWJYUxK0JBN",
        "colab_type": "text"
      },
      "source": [
        "**Adamax**\n",
        "\n",
        "Test loss: 0.11826916954151595\n",
        "\n",
        "\n",
        "Test accuracy: 0.9851"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN-m8uTByrY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hog5uwzZ0V1F",
        "colab_type": "text"
      },
      "source": [
        "**Nadam**\n",
        "\n",
        "Test loss: 0.12597350687139072\n",
        "\n",
        "\n",
        "Test accuracy: 0.9813"
      ]
    }
  ]
}